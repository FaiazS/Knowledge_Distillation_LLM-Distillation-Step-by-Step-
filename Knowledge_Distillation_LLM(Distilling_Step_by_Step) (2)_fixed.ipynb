{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FO7vpslfNf0N",
    "outputId": "8e4211c7-3912-44ee-9465-42fd3b996eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HIHTuNOSN-iu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-MdLjh12Hpr",
    "outputId": "9c6484a7-1518-4a25-83d5-89850726e8d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "student_model = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "student_llm_model = AutoModelForSequenceClassification.from_pretrained(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enHqkHew2x7h",
    "outputId": "9088e773-8da5-4b48-baa2-b2ab0d64ab0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(student_llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J1aZFTFo3J6h"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"sst2\",split = \"train[:10]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Psxvm2JG4Ubo",
    "outputId": "e10103ae-8a85-42a2-dfae-db4fdd5bb492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'sentence', 'label'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQqGPIMo4ag2",
    "outputId": "87ef149a-0122-4c6e-e3b4-98867ce370e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'sentence': 'hide new secretions from the parental units ', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b02C3CzI88dA",
    "outputId": "aa36c0a9-4686-40c4-c133-0eae679da278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama) (0.4.7)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama) (0.3.51)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.3.24)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (4.13.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.11.2)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-ollama) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n",
    "\n",
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "A1qsNurq-cLk"
   },
   "outputs": [],
   "source": [
    "#from langchain_ollama import ChatOllama\n",
    "\n",
    "#llm_chat_engine = ChatOllama(\n",
    "                             #model=\"deepseek-r1:7b\",\n",
    "                             #base_url=\"127.0.0.1:11434\",\n",
    "                             #temperature=0.3\n",
    "#)\n",
    "\n",
    "#test_prompt = \"I am very joyful today\"\n",
    "\n",
    "#student_llm_response = llm_chat_engine.invoke(test_prompt)\n",
    "\n",
    "#print(student_llm_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvZAullCSpGM",
    "outputId": "18e468c2-fa60-4cb3-af98-7f8c8a5f50fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.24)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.51)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.11.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.13.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.3.24)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (24.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "\n",
    "!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "370kNYwJTQe9"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = userdata.get('LLMProjectKey1')\n",
    "\n",
    "teacher_model = ChatGroq(\n",
    "\n",
    "                         model = \"deepseek-r1-distill-llama-70b\",\n",
    "\n",
    "                         temperature = 0.3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEe2snuBUiWF",
    "outputId": "d9e1f96d-ee83-4c04-b8ce-4b5e43f63f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out how to respond to the user's message. They said, \"I am very joyous today.\" Hmm, that's a positive statement. I should probably acknowledge their feelings and maybe ask a follow-up question to keep the conversation going.\n",
      "\n",
      "First, I want to express that I'm glad they're feeling joyous. Maybe start with something like, \"That's wonderful to hear!\" or \"I'm so glad you're feeling joyous today!\" Then, I should ask an open-ended question to encourage them to share more. Perhaps, \"What's making you feel so joyful today?\" or \"What's bringing you joy at the moment?\"\n",
      "\n",
      "Wait, I should make sure my response is friendly and supportive. Maybe add an emoji to convey warmth, like a smiley face or a heart. But I'm not sure if emojis are appropriate here. The user didn't use any, so maybe it's better to keep it professional.\n",
      "\n",
      "Alternatively, I could say something like, \"That's great! Would you like to share what's making you happy today?\" This way, I'm inviting them to elaborate without being too pushy.\n",
      "\n",
      "I also need to consider the tone. It should be upbeat and positive to match their mood. Maybe use words like \"delighted\" or \"thrilled\" to show genuine happiness for them.\n",
      "\n",
      "Wait, perhaps I can combine both the acknowledgment and the question into one sentence. For example, \"I'm so glad to hear you're feeling joyous today! What's behind your joy?\"\n",
      "\n",
      "No, that might be a bit formal. Maybe a more casual approach would be better, like \"That's awesome! Anything special happening that's got you feeling so good?\"\n",
      "\n",
      "I think that's a good balance. It acknowledges their feelings and invites them to share more without sounding too intrusive. Plus, using \"awesome\" keeps it casual and friendly.\n",
      "\n",
      "So, putting it all together, my response would be: \"That's awesome! Anything special happening that's got you feeling so good?\" That should work well to keep the conversation positive and engaging.\n",
      "</think>\n",
      "\n",
      "That's awesome! Anything special happening that's got you feeling so good?\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"I am very joyous today\"\n",
    "\n",
    "teacher_model_response = teacher_model.invoke(test_prompt)\n",
    "\n",
    "print(teacher_model_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kjCwJOyIVDqN"
   },
   "outputs": [],
   "source": [
    "def generate_model_reasoning(input_text):\n",
    "\n",
    "  \"\"\"\n",
    "  Uses Groq's Deepseek R1 Model to generate a step by step Rationale(Reasoning) for the Output given for particular Input(User prompt)\n",
    "  \"\"\"\n",
    "\n",
    "  user_prompt = f\"Deliver step by step reasoning before responding to: {input_text}\" #Chain of thoughts prompting request for Step by Step Distillation\n",
    "\n",
    "  teacher_model_response = teacher_model.invoke(user_prompt)\n",
    "\n",
    "  return teacher_model_response.content if hasattr(teacher_model_response, \"content\") else teacher_model_response\n",
    "\n",
    "teacher_model_response = generate_model_reasoning(\"Explain AI Agents and the technologies used behind the same, keep in mind it should be widely adopted in Industry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mPdBr2-YIPq",
    "outputId": "b39c374d-e454-4bc0-e84d-e9203a8d50ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to explain AI agents and the technologies behind them, especially focusing on how they're widely adopted in industries. Hmm, where do I start? I remember AI agents are like autonomous entities that can perform tasks on their own, but I'm not entirely sure. Maybe I should break it down.\n",
      "\n",
      "First, I think I should define what an AI agent is. From what I've heard, an AI agent is a program that uses AI to make decisions and act on its own. It interacts with an environment, right? So, it's not just a tool that does one thing; it's more like a system that can adapt and learn.\n",
      "\n",
      "Next, I need to outline the key characteristics. I remember something about autonomy, meaning they can operate without human intervention. Then there's reactivity, so they can respond to changes. Proactivity might be another trait, where they take initiative. Also, social ability, interacting with other agents or humans. Learning and adaptation are probably important too, as they improve over time.\n",
      "\n",
      "Now, the technologies behind AI agents. I think machine learning is a big one. There are different types like supervised, unsupervised, and reinforcement learning. Each has its own role. For example, reinforcement learning is used in game-playing AI like AlphaGo. Natural Language Processing (NLP) must be another key tech, handling human language for chatbots or voice assistants. Computer vision is probably involved for tasks like object recognition or facial recognition. Then there's the decision-making part, maybe using techniques like MDPS or game theory. The environment where agents operate is also importantâ€”could be physical, like robots, or virtual, like software agents.\n",
      "\n",
      "Applications in industries... Let's see. In healthcare, maybe virtual assistants help with diagnosis or patient care. In manufacturing, autonomous robots could handle tasks on the assembly line. Customer service uses chatbots for support. Finance might employ AI agents for fraud detection or trading. Transportation has self-driving cars. Supply chain could optimize logistics. Energy management might use agents to monitor and control systems.\n",
      "\n",
      "Looking at the technologies used, machine learning frameworks like TensorFlow or PyTorch are essential. NLP libraries such as NLTK or spaCy would be used for language tasks. Computer vision could use OpenCV. For decision-making, maybe tools like Gurobi for optimization. Integration with IoT devices would involve platforms like AWS IoT or Azure IoT Hub. Cloud platforms are necessary for scalability, so AWS, Azure, Google Cloud. For robotics, ROS is a known framework.\n",
      "\n",
      "Challenges and considerations... Data privacy is a big one, especially with regulations like GDPR. Explainability is important so that decisions can be understood. Scalability is needed as industries grow. Security is crucial to prevent breaches. Ethical considerations to ensure AI is used responsibly.\n",
      "\n",
      "In conclusion, AI agents are versatile and can be applied across many industries. The technologies involved are diverse, from ML to NLP and vision, each contributing to the agent's capabilities. As industries adopt these agents, they face challenges that need careful handling.\n",
      "\n",
      "Wait, did I miss anything? Maybe some examples or more detailed explanations on each technology? Or perhaps the difference between types of learning? I think I covered the main points, but maybe I should elaborate more on how each technology specifically contributes to AI agents in different industries. Also, maybe touch on future trends or advancements that could impact AI agents in the industry. But I guess the user wanted a concise explanation, so maybe that's enough for now.\n",
      "</think>\n",
      "\n",
      "**Explanation of AI Agents and Their Technologies in Industrial Applications**\n",
      "\n",
      "**Introduction to AI Agents:**\n",
      "AI agents are autonomous programs that utilize artificial intelligence to make decisions and act independently. They interact with their environment, adapting and learning to perform tasks without constant human intervention.\n",
      "\n",
      "**Key Characteristics:**\n",
      "1. **Autonomy:** Operate without human control.\n",
      "2. **Reactivity:** Respond to environmental changes.\n",
      "3. **Proactivity:** Take initiative based on goals.\n",
      "4. **Social Ability:** Interact with humans or other agents.\n",
      "5. **Learning/Adaptation:** Improve over time through experience.\n",
      "\n",
      "**Underlying Technologies:**\n",
      "1. **Machine Learning (ML):** Enables decision-making and learning through supervised, unsupervised, or reinforcement methods.\n",
      "2. **Natural Language Processing (NLP):** Facilitates interaction through text or speech, used in chatbots and virtual assistants.\n",
      "3. **Computer Vision:** Allows agents to interpret visual data, crucial for tasks like object recognition.\n",
      "4. **Decision-Making:** Techniques like MDPs and game theory enable strategic actions.\n",
      "5. **Environment Interaction:** Operates in physical (e.g., robots) or virtual (e.g., software) settings.\n",
      "\n",
      "**Industrial Applications:**\n",
      "- **Healthcare:** Virtual assistants aid in diagnosis and patient care.\n",
      "- **Manufacturing:** Autonomous robots perform assembly tasks.\n",
      "- **Customer Service:** Chatbots provide 24/7 support.\n",
      "- **Finance:** Agents detect fraud and execute trades.\n",
      "- **Transportation:** Self-driving cars navigate autonomously.\n",
      "- **Supply Chain:** Optimize logistics and inventory.\n",
      "- **Energy:** Monitor and control energy systems.\n",
      "\n",
      "**Technologies Used:**\n",
      "- **ML Frameworks:** TensorFlow, PyTorch.\n",
      "- **NLP Libraries:** NLTK, spaCy.\n",
      "- **Vision Tools:** OpenCV.\n",
      "- **Decision-Making Tools:** Gurobi.\n",
      "- **IoT Integration:** AWS IoT, Azure IoT Hub.\n",
      "- **Cloud Platforms:** AWS, Azure, Google Cloud.\n",
      "- **Robotics Frameworks:** ROS.\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "- **Data Privacy:** Compliance with regulations like GDPR.\n",
      "- **Explainability:** Ensuring decisions are understandable.\n",
      "- **Scalability:** Handling growth across industries.\n",
      "- **Security:** Protecting against breaches.\n",
      "- **Ethics:** Ensuring responsible AI use.\n",
      "\n",
      "**Conclusion:**\n",
      "AI agents are versatile tools across industries, leveraging technologies like ML, NLP, and vision. As industries adopt these agents, addressing challenges like privacy and ethics is crucial for sustainable integration. Future advancements may further enhance their capabilities and applications.\n"
     ]
    }
   ],
   "source": [
    "print(teacher_model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lytyYWvIYYda"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "6b2d2c8484284f65999d50c21c74f673",
      "c060408492134b5399cb0655c89682a7",
      "d93c2f727b7a4b19882afa5e1735858f",
      "6d012961248740ba9fa71b8737068658",
      "c59453caa7a948ef80e3ba7d4116b1ac",
      "bb36e0528f4e4b2a8738b8d77af482f9",
      "06bb83ae6f6b445f81d8a13280676827",
      "8cfbf246b3d34278863a156635c1acf3",
      "277409eb9250433ea1bb2564b4be0b7c",
      "7335788104df4ac5a89d33d548226df6",
      "560886f4f164463186bdaad33d78240f"
     ]
    },
    "id": "1Iy6sYLAZqMS",
    "outputId": "d081f855-08ed-4089-c2b6-c6201c3508fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function process_data at 0x78b425ac13a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "WARNING:datasets.fingerprint:Parameter 'function'=<function process_data at 0x78b425ac13a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2d2c8484284f65999d50c21c74f673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prepare datasets with Rationales(Reasoning)\n",
    "\n",
    "def process_data(example):\n",
    "\n",
    "  input_text = example[\"sentence\"]\n",
    "\n",
    "  reasoning = generate_model_reasoning(input_text)\n",
    "\n",
    "  label = example[\"label\"]\n",
    "\n",
    "  #Tokenizing input and rationale/reasoning\n",
    "\n",
    "  input_tokens = llm_tokenizer(input_text, truncation =\"longest_first\", padding = True, max_length = 256)\n",
    "\n",
    "  reasoning_tokens = llm_tokenizer(reasoning, truncation = \"longest_first\", padding = True, max_length = 256)\n",
    "\n",
    "  return {\n",
    "\n",
    "          \"input_ids\" : input_tokens[\"input_ids\"],\n",
    "\n",
    "          \"attention_mask\" : input_tokens[\"attention_mask\"],\n",
    "\n",
    "          \"labels\" : label,\n",
    "\n",
    "          \"reasoning_ids \" : reasoning_tokens[\"input_ids\"],\n",
    "\n",
    "          \"reasoning_mask\" : reasoning_tokens[\"attention_mask\"]\n",
    "  }\n",
    "\n",
    "processed_dataset = dataset.map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSv02GhUeCR-",
    "outputId": "2e00899d-2be6-4c0a-c81a-54fce7ac2600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask', 'labels', 'reasoning_ids ', 'reasoning_mask'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "129290cd001047178491bbfa1f68033e",
      "9bbf9c2d82a2426788bc3beaff1f22f6",
      "8169f78004264fbf8f387077ef49b592",
      "300e9181fb154fc6bed3621614a72913",
      "84894af017ec42d1b6f2b4ae05832572",
      "761cf5eea50e4d0c8c12d26b7056eb12",
      "01a05360d6c14ab6abdd5be8bfb00296",
      "ffe18b19d11841b5b0387f061bf55309",
      "b05f2f073cd0409984767adb2985b276",
      "89bec5475a884511abc5b719fa6a9a0f",
      "ff5d68dcf0434a7aa5ff28fbad13176a"
     ]
    },
    "id": "pcWicpmemCcN",
    "outputId": "6b481336-0332-4c1d-f750-baa5e58d873f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129290cd001047178491bbfa1f68033e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "processed_dataset.save_to_disk('preprocessed_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEOZIyklmmg9",
    "outputId": "6c931f6e-d66f-4e3f-b9ff-e9c274912331"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask', 'labels', 'reasoning_ids ', 'reasoning_mask'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "processed_dataset.load_from_disk('preprocessed_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "I5XY0xSEm0j9",
    "outputId": "69219baf-d796-4147-cd00-f6124943e699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.26.0 in /usr/local/lib/python3.11/dist-packages (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (0.30.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.26.0) (1.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.26.0) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.26.0) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfaiazrex8\u001b[0m (\u001b[33mfaiazrex8-scaler\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250413_200043-442ibuhc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/faiazrex8-scaler/huggingface/runs/442ibuhc' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/faiazrex8-scaler/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/faiazrex8-scaler/huggingface' target=\"_blank\">https://wandb.ai/faiazrex8-scaler/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/faiazrex8-scaler/huggingface/runs/442ibuhc' target=\"_blank\">https://wandb.ai/faiazrex8-scaler/huggingface/runs/442ibuhc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 01:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.419531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.347946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.5225234429041544, metrics={'train_runtime': 77.9763, 'train_samples_per_second': 0.385, 'train_steps_per_second': 0.077, 'total_flos': 398777693280.0, 'train_loss': 0.5225234429041544, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the Student Model To Understand the Rationale/Reasoning Generated/Drawn by the Teacher Model and also the Labels\n",
    "\n",
    "!pip install -U 'accelerate==0.26.0'\n",
    "\n",
    "import accelerate\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "accelerate.__version__\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "\n",
    "                                       output_dir = \"./results\",\n",
    "\n",
    "                                       eval_strategy = \"epoch\",\n",
    "\n",
    "                                       learning_rate = 5e-5,\n",
    "\n",
    "                                       per_device_train_batch_size = 8,\n",
    "\n",
    "                                       per_device_eval_batch_size = 8,\n",
    "\n",
    "                                       num_train_epochs = 3,\n",
    "\n",
    "                                       weight_decay = 0.01,\n",
    "\n",
    "                                       save_strategy = \"epoch\",\n",
    "\n",
    "                                       push_to_hub = False,\n",
    "\n",
    ")\n",
    "\n",
    "class MultiTaskTrainer(Trainer):\n",
    "\n",
    "  def compute_loss(self, model, inputs, return_outputs = False, num_items_in_batch = None, **kwargs):\n",
    "\n",
    "    labels = inputs.pop(\"labels\")\n",
    "\n",
    "    reasoning_ids = inputs.pop(\"reasoning_ids\", None)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    label_loss = loss_function(outputs.logits, labels)\n",
    "\n",
    "    if reasoning_ids is not None:\n",
    "\n",
    "      reasoning_outputs = model(input_ids = reasoning_ids, attention_mask = inputs[\"attention_mask\"])\n",
    "\n",
    "      reasoning_loss = loss_function(reasoning_outputs.logits, reasoning_ids)\n",
    "\n",
    "      loss = label_loss + 0.5 * reasoning_loss\n",
    "\n",
    "    else:\n",
    "\n",
    "      loss = label_loss\n",
    "\n",
    "\n",
    "    return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "student_model_trainer = MultiTaskTrainer(\n",
    "\n",
    "                                         model = student_llm_model,\n",
    "\n",
    "                                         args = training_arguments,\n",
    "\n",
    "                                         train_dataset = processed_dataset,\n",
    "\n",
    "                                         eval_dataset = processed_dataset,\n",
    "\n",
    "                                         data_collator = DataCollatorWithPadding(tokenizer = llm_tokenizer)\n",
    ")\n",
    "\n",
    "student_model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2gtDnEdIAGh",
    "outputId": "f0f98b8d-dcb6-413b-ad9d-6d80292f6b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask', 'labels', 'reasoning_ids ', 'reasoning_mask'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RjmGX2JKYR1",
    "outputId": "855f7781-be75-4a39-eacf-d6f1fe5cb02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation Complete! Student Model and Tokenzier Saved!\n"
     ]
    }
   ],
   "source": [
    "student_model_save_path = \"./result\"\n",
    "\n",
    "student_model_trainer.save_model(student_model_save_path)\n",
    "\n",
    "llm_tokenizer.save_pretrained(student_model_save_path)\n",
    "\n",
    "print(\"Distillation Complete! Student Model and Tokenzier Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plKlDTJgfzpS",
    "outputId": "759e95b4-2496-4994-bf4a-60a19567ba71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment class 1\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Student Model\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(student_model_save_path)\n",
    "\n",
    "llm_model_tokenizer = AutoTokenizer.from_pretrained(student_model_save_path)\n",
    "\n",
    "student_model.eval()\n",
    "\n",
    "def predict_sentiment(input_text):\n",
    "\n",
    "    input_tokens = llm_model_tokenizer(input_text, return_tensors = \"pt\", padding = True, truncation = True, max_length = 512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      output_tokens = student_model(**input_tokens)\n",
    "\n",
    "      logits = output_tokens.logits\n",
    "\n",
    "      predicted_sentiment_class = torch.argmax(logits, dim = -1).item()\n",
    "\n",
    "    return predicted_sentiment_class\n",
    "\n",
    "\n",
    "#Testing the Student Model\n",
    "\n",
    "user_input_text = \"are more deeply thought through than in most right thinking films\"\n",
    "\n",
    "sentiment_prediction = predict_sentiment(user_input_text)\n",
    "\n",
    "print(\"Predicted sentiment class\", sentiment_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_5QgxOH05Pf",
    "outputId": "f93bed07-6f4f-4306-f910-60f3bb2e7127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the sentiment of the sentence \"I am very happy today!\" Hmm, let's break this down. First, the word \"happy\" is a strong indicator of positive emotion. The use of \"very\" emphasizes the intensity of the happiness, which makes the sentiment even more positive. There are no negative words here, so it's not like a mixed sentiment. The exclamation mark at the end also adds to the enthusiasm, showing that the speaker is really feeling upbeat. I don't see any negative terms or context that might suggest otherwise. So, putting it all together, the sentiment is definitely positive.\n",
      "</think>\n",
      "\n",
      "The sentiment of the input \"I am very happy today!\" is **positive**. The use of the word \"happy\" and the emphasis with \"very\" clearly indicate a positive emotional state.\n"
     ]
    }
   ],
   "source": [
    "#Giving new input and testing\n",
    "\n",
    "model_test_prompt = \"Predict the sentiment for this input - I am very happy today!\"\n",
    "\n",
    "model_response = teacher_model.invoke(model_test_prompt)\n",
    "\n",
    "print(model_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zrYoZCf77AU",
    "outputId": "58cf3f4d-6cce-4aea-872c-a656e76374bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at ./result and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am very joyful person!ighalitysibleersonÙ¹duk guerrarandtinorandrrowuncetureital stressesÊŠbangrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowrrowumbliprrowrrowrrowrrowrrow\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "student_llm_model = AutoModelForCausalLM.from_pretrained(student_model_save_path)\n",
    "\n",
    "student_llm_model_tokenizer = AutoTokenizer.from_pretrained(student_model_save_path)\n",
    "\n",
    "student_llm_model.eval()\n",
    "\n",
    "\n",
    "def generate_model_response(input_prompt, max_length = 100):\n",
    "\n",
    "  input_tokens = student_llm_model_tokenizer(input_prompt, return_tensors = \"pt\", padding = True, truncation = True)\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    output_tokens = student_llm_model.generate(**input_tokens, max_length = max_length)\n",
    "\n",
    "  student_llm_model_response = student_llm_model_tokenizer.decode(output_tokens[0], skip_special_tokens = True)\n",
    "\n",
    "  return student_llm_model_response\n",
    "\n",
    "test_prompt = \"I am very joyful person!\"\n",
    "\n",
    "student_llm_model_response = generate_model_response(test_prompt)\n",
    "\n",
    "print(student_llm_model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_KBrDfrVw5jo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_points = {\n",
    "\n",
    "        \"text\": [],\n",
    "\n",
    "        \"reasoning\" : [],\n",
    "\n",
    "        \"target\" : []\n",
    "}\n",
    "\n",
    "for example in dataset:\n",
    "\n",
    "  input_text = example[\"sentence\"]\n",
    "\n",
    "  reasoning = generate_model_reasoning(input_text)\n",
    "\n",
    "  label = example[\"label\"]\n",
    "\n",
    "  data_points[\"text\"].append(input_text)\n",
    "\n",
    "  data_points[\"reasoning\"].append(reasoning)\n",
    "\n",
    "  data_points[\"target\"].append(label)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_points)\n",
    "\n",
    "df.to_csv(\"train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPG5h2BI3UP3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
